{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fda727b",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71a1da",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d0d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd36eb",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e12fba7",
   "metadata": {},
   "source": [
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2431fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea06d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to wikipedia.org\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fe0b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to scrap the data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811b10f",
   "metadata": {},
   "source": [
    "# Scraping the data from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7a7fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Try and except Block\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//tbody//tr//td[1]\")[:30]:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6360177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping video names \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//tbody//tr//td[2]\")[:30]:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "19669b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of artist name\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//tbody//tr//td[3]\")[:30]:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:        \n",
    "    Artist.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65f4accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping upload dates\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//tbody//tr//td[5]\")[:30]:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException:        \n",
    "    Upload_date.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e08be7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of views\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//tbody//tr//td[4]\")[:30]:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73925c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "#printing the length of each list \n",
    "print(len(Rank),len(Name),len(Artist),len(Upload_date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1ecd6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a DataFrame\n",
    "\n",
    "Youtube=pd.DataFrame({})\n",
    "Youtube['Rank'] = Rank\n",
    "Youtube['Name'] = Name\n",
    "Youtube['Artist'] = Artist\n",
    "Youtube['Uploaded Date'] = Upload_date\n",
    "Youtube['Views'] = Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6fe58d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Uploaded Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[24]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[25]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[36]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Girls Like You\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Faded\"[39]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Shake It Off\"[46]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[47]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Mi Gente\"[48]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
       "10  11.                              \"Gangnam Style\"[25]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                          \"Thinking Out Loud\"[36]   \n",
       "18  19.                                     \"Axel F\"[37]   \n",
       "19  20.                             \"Girls Like You\"[38]   \n",
       "20  21.                                      \"Faded\"[39]   \n",
       "21  22.                                 \"Dark Horse\"[40]   \n",
       "22  23.                        \"Baa Baa Black Sheep\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.                               \"Shake It Off\"[46]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[47]   \n",
       "29  30.                                   \"Mi Gente\"[48]   \n",
       "\n",
       "                                         Artist      Uploaded Date  Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  10.80  \n",
       "1                                    Luis Fonsi   January 12, 2017   7.87  \n",
       "2                                   LooLoo Kids    October 8, 2016   6.37  \n",
       "3                                    Ed Sheeran   January 30, 2017   5.74  \n",
       "4                                   Wiz Khalifa      April 6, 2015   5.54  \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   5.44  \n",
       "6                                     ChuChu TV      March 6, 2014   4.67  \n",
       "7                                   Mark Ronson  November 19, 2014   4.60  \n",
       "8                                   Miroshka TV  February 27, 2018   4.58  \n",
       "9                                    Get Movies   January 31, 2012   4.50  \n",
       "10                                          Psy      July 15, 2012   4.45  \n",
       "11                   Cocomelon – Nursery Rhymes       May 24, 2018   4.12  \n",
       "12                                    El Chombo      April 5, 2018   3.95  \n",
       "13                                     Maroon 5   January 14, 2015   3.71  \n",
       "14                                   Katy Perry  September 5, 2013   3.60  \n",
       "15                                  OneRepublic       May 31, 2013   3.59  \n",
       "16                                Justin Bieber   October 22, 2015   3.55  \n",
       "17                                   Ed Sheeran    October 7, 2014   3.46  \n",
       "18                                   Crazy Frog      June 16, 2009   3.38  \n",
       "19                                     Maroon 5       May 31, 2018   3.30  \n",
       "20                                  Alan Walker   December 3, 2015   3.29  \n",
       "21                                   Katy Perry  February 20, 2014   3.29  \n",
       "22                   Cocomelon – Nursery Rhymes      June 25, 2018   3.26  \n",
       "23                                    Passenger      July 25, 2012   3.24  \n",
       "24                             Enrique Iglesias     April 11, 2014   3.22  \n",
       "25                                  Major Lazer     March 22, 2015   3.22  \n",
       "26                                   Ed Sheeran   November 9, 2017   3.18  \n",
       "27                                 Taylor Swift    August 18, 2014   3.18  \n",
       "28                                      Shakira       June 4, 2010   3.16  \n",
       "29                                     J Balvin      June 29, 2017   3.09  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the data frame\n",
    "Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6249e72",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c220320",
   "metadata": {},
   "source": [
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "edb29378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fbe7228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of bcci.tv\n",
    "url = \"https://www.bcci.tv/.\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "09f12f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the data for international fixture and clicking on it\n",
    "driver.find_element_by_xpath(\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f8648cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting International Fixtures\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div/ul/li[1]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "86d5f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for India\n",
    "search=driver.find_element_by_xpath(\"/html/body/nav/div[2]/form/div/button\")\n",
    "time.sleep(2)\n",
    "search.send_keys('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8d26811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Match_title=[]\n",
    "ODI=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bd3af40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data for Match title\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='ng-binding']\"):\n",
    "        Match_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Match_title.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93e042d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data for ODI\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='fix-place ng-binding ng-scope']\"):\n",
    "        ODI.append(i.text.split('-')[0])\n",
    "except NoSuchElementException:\n",
    "    ODI.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "993d92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the data for place\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='fix-place ng-binding ng-scope']\"):\n",
    "        Place.append(i.text.split('-')[-1])\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "edb0839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the data for date\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//h5[@class='ng-binding']\"):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e92518a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the data for time\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//h5[@class='text-right ng-binding']\"):\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f47c05a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "#printing the length of each list \n",
    "print(len(ODI),len(Match_title),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eaa0b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(zip(ODI, Match_title,Place, Date, Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "44ac42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a dataframe\n",
    "df=pd.DataFrame(data,columns=['ODI','Match_Series','Place','Date','Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cbf0724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODI</th>\n",
       "      <th>Match_Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF SRI LANKA T20 SERIES 2022</td>\n",
       "      <td>Rangiri Dambulla International Stadium, Dambulla</td>\n",
       "      <td>23 JUN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF SRI LANKA T20 SERIES 2022</td>\n",
       "      <td>Rangiri Dambulla International Stadium, Dambulla</td>\n",
       "      <td>25 JUN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND T20 SERIES 2022</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>26 JUN 2022</td>\n",
       "      <td>9:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF SRI LANKA T20 SERIES 2022</td>\n",
       "      <td>Rangiri Dambulla International Stadium, Dambulla</td>\n",
       "      <td>27 JUN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND T20 SERIES 2022</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>28 JUN 2022</td>\n",
       "      <td>9:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF SRI LANKA ODI SERIES 2022</td>\n",
       "      <td>Pallekele International Cricket Stadium, Pall...</td>\n",
       "      <td>1 JUL 2022</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>INDIA TOUR OF ENGLAND TEST SERIES 2021</td>\n",
       "      <td>Edgbaston, Birmingham</td>\n",
       "      <td>1 JUL 2022</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF SRI LANKA ODI SERIES 2022</td>\n",
       "      <td>Pallekele International Cricket Stadium, Pall...</td>\n",
       "      <td>4 JUL 2022</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ODI                                   Match_Series  \\\n",
       "0  1st T20I   INDIA WOMEN TOUR OF SRI LANKA T20 SERIES 2022   \n",
       "1  2nd T20I   INDIA WOMEN TOUR OF SRI LANKA T20 SERIES 2022   \n",
       "2  1st T20I           INDIA TOUR OF IRELAND T20 SERIES 2022   \n",
       "3  3rd T20I   INDIA WOMEN TOUR OF SRI LANKA T20 SERIES 2022   \n",
       "4  2nd T20I           INDIA TOUR OF IRELAND T20 SERIES 2022   \n",
       "5   1st ODI   INDIA WOMEN TOUR OF SRI LANKA ODI SERIES 2022   \n",
       "6  5th Test          INDIA TOUR OF ENGLAND TEST SERIES 2021   \n",
       "7   2nd ODI   INDIA WOMEN TOUR OF SRI LANKA ODI SERIES 2022   \n",
       "\n",
       "                                               Place         Date  \\\n",
       "0   Rangiri Dambulla International Stadium, Dambulla  23 JUN 2022   \n",
       "1   Rangiri Dambulla International Stadium, Dambulla  25 JUN 2022   \n",
       "2                                The Village, Dublin  26 JUN 2022   \n",
       "3   Rangiri Dambulla International Stadium, Dambulla  27 JUN 2022   \n",
       "4                                The Village, Dublin  28 JUN 2022   \n",
       "5   Pallekele International Cricket Stadium, Pall...   1 JUL 2022   \n",
       "6                              Edgbaston, Birmingham   1 JUL 2022   \n",
       "7   Pallekele International Cricket Stadium, Pall...   4 JUL 2022   \n",
       "\n",
       "           Time  \n",
       "0   2:00 PM IST  \n",
       "1   2:00 PM IST  \n",
       "2   9:00 PM IST  \n",
       "3   2:00 PM IST  \n",
       "4   9:00 PM IST  \n",
       "5  10:00 AM IST  \n",
       "6   3:30 PM IST  \n",
       "7  10:00 AM IST  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #printing the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e3b05",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "555ffb66",
   "metadata": {},
   "source": [
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c806de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c522bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.guru99.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f5fdf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navigating to the search bar and searching for selenium exception\n",
    "ser_bar = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[1]/div[2]/div/div[1]/div/div/div/form/table/tbody/tr/td[1]/div/table/tbody/tr/td[1]/input\")\n",
    "ser_bar.send_keys(\"selenium exception handling\")\n",
    "ser_but = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[1]/div[2]/div/div[1]/div/div/div/form/table/tbody/tr/td[2]/button\").click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4e71affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Url of selenium exception handling page\n",
    "urls = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]/li[3]/a\")\n",
    "page_url = urls.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7999eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of names of exceptions\n",
    "\n",
    "#creating an empty list to store scraped data\n",
    "Name = []\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']//tr//td[1]\")[1:]:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5d6c2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of descriptions of exceptions  \n",
    "\n",
    "#creating an empty list \n",
    "Description = []\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']//tr//td[2]\")[1:]:\n",
    "    Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f97cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe\n",
    "Guru99=pd.DataFrame({})\n",
    "Guru99['Name of Exception'] = Name\n",
    "Guru99['Description of Exception'] = Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "17f2507d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the dataframe\n",
    "Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc13516",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5056980",
   "metadata": {},
   "source": [
    "urls = driver.find_element_by_xpath(\"//div[@class='dropdown-content']//a[3]\")\n",
    "ineco_page = urls.get_attribute(\"href\")\n",
    "#Going to indian economy page\n",
    "driver.get(ineco_page)  \n",
    "time.sleep(5)url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d7dbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90698bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "640a9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on economy section\n",
    "economy = driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f057bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "ineco_page = urls.get_attribute(\"href\")\n",
    "\n",
    "#Going to indian economy page\n",
    "driver.get(ineco_page)  \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d01637fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP_1 = []\n",
    "GSDP_2 = []\n",
    "Share = []\n",
    "GDP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a5ddc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the url of page containing GDP of indian states\n",
    "sta_GDP = driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP_url = sta_GDP.get_attribute(\"href\")\n",
    "\n",
    "driver.get(GDP_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7be794a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data\n",
    "\n",
    "#Scraping data of rank\n",
    "for i in driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']//tbody//tr//td[1]\"):\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "50643ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of state name\n",
    "for i in driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']//tbody//tr//td[2]\"):\n",
    "    State.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5d9150f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data of GSDP at current price \n",
    "for i in driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']//tbody//tr//td[3]\"):\n",
    "    GSDP_1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b2e34c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of GSDP at current price (18-19)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']//tbody//tr//td[4]\"):\n",
    "    GSDP_2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8e2e2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Share(18-19)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']//tbody//tr//td[5]\"):\n",
    "    Share.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "143ee26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of GDP($ billion)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']//tbody//tr//td[6]\"):\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f95f51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFraming\n",
    "data=list(zip(Rank,State,GSDP_1,GSDP_2,Share,GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7a05dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe\n",
    "df=pd.DataFrame(data,columns=['Rank','Indian_State','GSDP(19-20)','GSDP(18-19)','Share','GDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4db63ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Indian_State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank               Indian_State GSDP(19-20) GSDP(18-19)   Share      GDP\n",
       "0     1                Maharashtra           -   2,632,792  13.94%  399.921\n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208   8.63%  247.629\n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764   8.39%  240.726\n",
       "3     4                    Gujarat           -   1,502,899   7.96%  228.290\n",
       "4     5                  Karnataka   1,631,977   1,493,127   7.91%  226.806\n",
       "5     6                West Bengal   1,253,832   1,089,898   5.77%  165.556\n",
       "6     7                  Rajasthan   1,020,989     942,586   4.99%  143.179\n",
       "7     8             Andhra Pradesh     972,782     862,957   4.57%  131.083\n",
       "8     9                  Telangana     969,604     861,031   4.56%  130.791\n",
       "9    10             Madhya Pradesh     906,672     809,592   4.29%  122.977\n",
       "10   11                     Kerala           -     781,653   4.14%  118.733\n",
       "11   12                      Delhi     856,112     774,870   4.10%  117.703\n",
       "12   13                    Haryana     831,610     734,163   3.89%  111.519\n",
       "13   14                      Bihar     611,804     530,363   2.81%   80.562\n",
       "14   15                     Punjab     574,760     526,376   2.79%   79.957\n",
       "15   16                     Odisha     521,275     487,805   2.58%   74.098\n",
       "16   17                      Assam           -     315,881   1.67%   47.982\n",
       "17   18               Chhattisgarh     329,180     304,063   1.61%   46.187\n",
       "18   19                  Jharkhand     328,598     297,204   1.57%   45.145\n",
       "19   20                Uttarakhand           -     245,895   1.30%   37.351\n",
       "20   21            Jammu & Kashmir           -     155,956   0.83%   23.690\n",
       "21   22           Himachal Pradesh     165,472     153,845   0.81%   23.369\n",
       "22   23                        Goa      80,449      73,170   0.39%   11.115\n",
       "23   24                    Tripura      55,984      49,845   0.26%    7.571\n",
       "24   25                 Chandigarh           -      42,114   0.22%    6.397\n",
       "25   26                 Puducherry      38,253      34,433   0.18%    5.230\n",
       "26   27                  Meghalaya      36,572      33,481   0.18%    5.086\n",
       "27   28                     Sikkim      32,496      28,723   0.15%    4.363\n",
       "28   29                    Manipur      31,790      27,870   0.15%    4.233\n",
       "29   30                   Nagaland           -      27,283   0.14%    4.144\n",
       "30   31          Arunachal Pradesh           -      24,603   0.13%    3.737\n",
       "31   32                    Mizoram      26,503      22,287   0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands           -           -       -        -"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e27da",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8777db12",
   "metadata": {},
   "source": [
    "#getting the desired webpage.\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "be8e0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7ff62bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f393be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the explore button\n",
    "explore = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b91503d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the popular options\n",
    "trend_url = driver.find_element_by_xpath(\"/html/body/div[1]/header/div[1]/div[2]/nav/ul/li[4]/details/div[1]/ul[1]/li[3]/a\")\n",
    "urls = trend_url.get_attribute(\"href\")\n",
    "driver.get(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "301c02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "34e3cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data from each repository\n",
    "repository = driver.find_elements_by_xpath(\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e67c5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Repository Title data\n",
    "title = driver.find_elements_by_xpath(\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "65e6d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8d5fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Repository Description data\n",
    "try:\n",
    "    desc = driver.find_element_by_xpath(\"//p[@class='f4 mt-3']\")\n",
    "    Description.append(desc.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "466d8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Contributors Count data\n",
    "try:\n",
    "    contributor = driver.find_element_by_xpath(\"//*[contains(text(),'    Contributors ')]\")\n",
    "    Contributors.append(contributor.text.replace('Contributors',''))\n",
    "except NoSuchElementException:\n",
    "    Contributors.append('-')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "95f04017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Languages used data\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='color-text-primary text-bold mr-1']\"):\n",
    "        lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "except NoSuchElementException:\n",
    "    Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7bb38db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a dataframe\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = repository_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df643dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Repository title Repository description Contributors count\n",
       "0               NaN                      -                  -"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48757d95",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a312e9f6",
   "metadata": {},
   "source": [
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f8c9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "44de6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https:/www.billboard.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6d4758b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts tab\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/header/div[1]/div/div/div[2]/div/nav/ul/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1405f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on hot 100 tab\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/header/div[2]/div/nav/ul/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cdf1f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6c912de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data of song names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\"):\n",
    "    Song_Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "48eb6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data of artist names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"):\n",
    "    Artist_Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8a663f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data of last week ranks\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\"):\n",
    "    Last_week_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc1db745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data of peak rank\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"):\n",
    "    Peak_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7f0736fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data of weeks on board\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\"):\n",
    "    Weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8e36df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe for scraped data\n",
    "billboard=pd.DataFrame({})\n",
    "billboard['Name'] = Song_Name\n",
    "billboard['Artist'] = Artist_Name\n",
    "billboard['Last week rank'] = Last_week_rank\n",
    "billboard['Peak rank'] = Peak_rank\n",
    "billboard['Weeks on board'] = Weeks_on_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5169dc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Artist, Last week rank, Peak rank, Weeks on board]\n",
       "Index: []"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159db062",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "602182e6",
   "metadata": {},
   "source": [
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d63594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8183c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a03632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching search button, sending keys and clicking on it\n",
    "search = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[1]/div/div/div/input\") \n",
    "search.send_keys(\"Data science \")           \n",
    "btn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\").click()     \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9837c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91497ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\"):\n",
    "    Name.append(i.text)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48b2d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Designation\n",
    "for i in driver.find_elements_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[2]/div[1]/div[1]/a\"):\n",
    "    Designation.append(i.text)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6082324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of company name\n",
    "for i in driver.find_elements_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[2]/div[1]/div[1]/div/a[1]\"):\n",
    "    Company.append(i.text)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dc7f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of Skills \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[1]/ul\"):\n",
    "    try:\n",
    "        if i.text == \"Not Specified\": raise NoSuchElementException\n",
    "        Skills.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Skills.append('-')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f951c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of locations\n",
    "for i in driver.find_elements_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div/ul/li[3]/span\"):\n",
    "    Location.append(i.text)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b03dace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe for scraped data\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name'] = Name[:50]\n",
    "Naukri['Designation'] = Designation[:50]\n",
    "Naukri['Company'] = Company[:50]\n",
    "Naukri['Skills'] = Skills[:50]\n",
    "Naukri['Location'] = Location[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69d5b4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Shell</td>\n",
       "      <td>data analysis\\nbig data analytics\\nConjoint\\nT...</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name           Designation Company  \\\n",
       "0   NaN  Data Science Analyst   Shell   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  data analysis\\nbig data analytics\\nConjoint\\nT...   \n",
       "\n",
       "                                           Location  \n",
       "0  Chennai, Bangalore/Bengaluru, Mumbai (All Areas)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the dataframe\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32058799",
   "metadata": {},
   "source": [
    "# 8. Scrape the details of Highest selling novels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76181298",
   "metadata": {},
   "source": [
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca0fc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97a2729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fb48bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty lists to store the scraping data\n",
    "Book_Name=[] \n",
    "Author_Name=[] \n",
    "Volumes_Sold=[]\n",
    "Publisher=[] \n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8563ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function\n",
    "book = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in book:\n",
    "    Book_Name.append(i.text)\n",
    "author = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in author:\n",
    "    Author_Name.append(i.text)\n",
    "vol = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in vol:\n",
    "    Volumes_Sold.append(i.text)\n",
    "pub = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in pub:\n",
    "    Publisher.append(i.text)\n",
    "gen = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in gen:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1272a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataframe from the scraped data\n",
    "Novel=pd.DataFrame({})\n",
    "Novel['Book Name']=Book_Name\n",
    "Novel['Author Name']= Author_Name\n",
    "Novel['Volumes Sold']=Volumes_Sold\n",
    "Novel['Publisher']=Publisher\n",
    "Novel['Genre']=Genre\n",
    "Novel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f9d2c",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4288a99c",
   "metadata": {},
   "source": [
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c60a5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46e1fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14ab488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9627fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b1a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Year span\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45e44aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of genre\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce50b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Run time\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "754bee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0480c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of votes\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ce949fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,998,743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,048,023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>951,105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>284,272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>244,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48,950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>59,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>190,955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>229,479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  1,998,743  \n",
       "1    51 min     8.7  1,048,023  \n",
       "2    44 min     8.2    951,105  \n",
       "3    60 min     7.5    284,272  \n",
       "4    43 min     7.6    244,060  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     48,950  \n",
       "96   50 min     7.8     59,660  \n",
       "97   42 min     8.1    190,955  \n",
       "98   45 min     7.1     40,382  \n",
       "99  572 min     8.6    229,479  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "IMDB=pd.DataFrame({})\n",
    "IMDB['Name'] = Name\n",
    "IMDB['Year Span'] = Year_span\n",
    "IMDB['Genre'] = Genre\n",
    "IMDB['Run Time'] = Run_time\n",
    "IMDB['Ratings'] = Ratings\n",
    "IMDB['Votes'] = Votes\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0555a",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "raw",
   "id": "679d7a4d",
   "metadata": {},
   "source": [
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c13b66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Asus\\Desktop\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a21dfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bdd2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding view all dataset button\n",
    "view_dataset = driver.find_element_by_xpath(\"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = view_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "394a79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting page urls containing list of all datasets\n",
    "all_lst = driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "lst_url = all_lst.get_attribute(\"href\")           \n",
    "driver.get(lst_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75585d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching url for each dataset\n",
    "data_url = driver.find_elements_by_xpath(\"//p[@class='normal']//b/a\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "895d8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []     \n",
    "for i in data_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eea07cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Data_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attr_type = []\n",
    "Instances = []\n",
    "n_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Dataset name\n",
    "    try: \n",
    "        ds_name = driver.find_element_by_xpath(\"//span[@class='heading']\")\n",
    "        Data_name.append(ds_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_name.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33750dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Scraping data type\n",
    "    try:\n",
    "        dtype = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if dtype.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(dtype.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Attribute type\n",
    "    try:\n",
    "        atype = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if atype.text == \"N/A\": raise NoSuchElementException\n",
    "        Attr_type.append(atype.text)\n",
    "    except NoSuchElementException:\n",
    "        Attr_type.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631193bb",
   "metadata": {},
   "outputs": [],
   "source": [
    " #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Scraping No of instances\n",
    "    try:\n",
    "        inst = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if inst.text == \"N/A\": raise NoSuchElementException\n",
    "        Instances.append(inst.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Scraping  No of attribute\n",
    "    try:\n",
    "        attr = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attr.text == \"N/A\": raise NoSuchElementException\n",
    "        n_attributes.append(attr.text)\n",
    "    except NoSuchElementException:\n",
    "        n_attributes.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #scraping year\n",
    "    try:\n",
    "        year = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #DATA FRAMEING\n",
    "UCI=pd.DataFrame({})\n",
    "UCI['Data Name'] = Data_name\n",
    "UCI['Data Type'] = Data_type\n",
    "UCI['Task'] = Task\n",
    "UCI['Attribute type'] = Attr_type\n",
    "UCI['No of instance'] = Instances\n",
    "UCI['No of attributes'] = n_attributes\n",
    "UCI['Year'] = Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732d815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
